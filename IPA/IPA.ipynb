{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QzuiRBsmzy_o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import warnings\n",
        "import time\n",
        "import multiprocessing\n",
        "import threading\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "# from google.colab import files\n",
        "warnings.filterwarnings('ignore', message='Unverified HTTPS request')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "rwIdMykezyXq",
        "outputId": "c912b518-dc54-4daf-b94a-8ac46fc6b09d"
      },
      "outputs": [],
      "source": [
        "# uploaded = files.upload()\n",
        "# df = pd.read_csv(io.BytesIO(uploaded[list(uploaded.keys())[0]]))\n",
        "df = pd.read_csv('only_sentence_with_punc.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lJBonx1HY2OV"
      },
      "outputs": [],
      "source": [
        "def subset_worker_words(subset):\n",
        "  print(subset)\n",
        "  for row in subset.itertuples():\n",
        "    print(f\"Started {row.Index}\")\n",
        "    if pd.notna(row.ipa):\n",
        "      print(f\"{row.Index}:{row.ipa}\")\n",
        "      continue\n",
        "    words=row.sentence.split(\" \")\n",
        "    if(len(words)>1):\n",
        "      datas=\"\"\n",
        "      for word in words:\n",
        "        # url= f\"http://ipa.bangla.gov.bd/post_text_bangla_ipa?bangla_ipa={word}\"\n",
        "        url= f\"http://127.0.0.1:5000//post_text_bangla_ipa?bangla_ipa={word}\"\n",
        "        response=None\n",
        "        try:\n",
        "          response = requests.get (url, verify=False)\n",
        "          if response and response.status_code == 200:\n",
        "            data= response.json()\n",
        "            datas=datas+\" \"+data[\"data\"][0]\n",
        "          else:\n",
        "            datas=datas+\" \"+\"ERROR\"\n",
        "        except:\n",
        "          print(f\"error at{row.Index}:{row.sentence}\")\n",
        "          datas=datas+\" \"+\"ERROR\"\n",
        "      print(f\"Ended {row.Index}\")\n",
        "      df.at[row.Index,\"ipa\"]=datas\n",
        "    else:\n",
        "      url = f\"http://ipa.bangla.gov.bd/post_text_bangla_ipa?bangla_ipa={row.sentence}\"\n",
        "      response=None\n",
        "      try:\n",
        "        response = requests.get (url, verify=False)\n",
        "        if response and response.status_code == 200:\n",
        "          data= response.json()\n",
        "          df.at[row.Index,\"ipa\"]=data[\"data\"][0]\n",
        "          print(f\"Ended {row.Index}:{row.sentence}\")\n",
        "          print(f\"{row.Index}:{data['data'][0]}\")\n",
        "        else:\n",
        "          data= None\n",
        "      except:\n",
        "        print(f\"error at{row.Index}:{row.sentence}\")\n",
        "  # df.to_csv(\"withIPA.csv\",index=False)\n",
        "  print(\"Done\")\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i7opiEwxBa4q"
      },
      "outputs": [],
      "source": [
        "def subset_worker(subset):\n",
        "  print(subset)\n",
        "  for row in subset.itertuples():\n",
        "    print(f\"Started{row.Index}\")\n",
        "    if pd.notna(row.ipa):\n",
        "      print(f\"{row.Index}:{row.ipa}\")\n",
        "      continue\n",
        "    url = f\"http://127.0.0.1:5000//post_text_bangla_ipa?bangla_ipa={row.sentence}\"\n",
        "    response=None\n",
        "    try:\n",
        "      response = requests.get (url, verify=False)\n",
        "      if response and response.status_code == 200:\n",
        "        data= response.json()\n",
        "        df.at[row.Index,\"ipa\"]=data[\"data\"][0]\n",
        "      else:\n",
        "        data= None\n",
        "    except:\n",
        "      print(f\"error at{row.Index}:{row.sentence}\")\n",
        "    print(f\"Ended {row.Index}\")\n",
        "    # print(f\"{row.Index}:{row.ipa}\")\n",
        "  # df.to_csv(\"withIPA.csv\",index=False)\n",
        "  print(\"Done\")\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def subset_worker_db(subset):\n",
        "  for row in subset.itertuples():\n",
        "    data=call_api(row.word)\n",
        "    if data:\n",
        "      print(f\"{row.Index}:{data['data'][0]}\")\n",
        "    else:\n",
        "      print(row.Index)\n",
        "      print(row.word)\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBDYF4RW2-SF"
      },
      "outputs": [],
      "source": [
        "# threadpool make sure everything is currect before running this cell\n",
        "start=0\n",
        "steps=100\n",
        "end=1000\n",
        "subsets=[]\n",
        "start_pos=start\n",
        "while start<end:\n",
        "  subsets.append(df.iloc[start:start+steps])\n",
        "  start=start+steps\n",
        "print(subsets)\n",
        "pool=ThreadPoolExecutor(len(subsets))\n",
        "ws=[]\n",
        "for subset in subsets:\n",
        "  ws.append(pool.submit(subset_worker_words, subset))\n",
        "print(pool.shutdown())\n",
        "df.to_csv(f\"only_sentence_with_punc_ipa{start_pos}_{end}.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wj5TZUl3iIX"
      },
      "outputs": [],
      "source": [
        "# Fills the empty ones\n",
        "subset1_1000=df.iloc[3000:6000]\n",
        "for row in subset1_1000.itertuples():\n",
        "  print(row.Index)\n",
        "  # print(row[1])\n",
        "  if pd.notna(row.ipa):\n",
        "    continue\n",
        "  print(row.sentence)\n",
        "  data=call_api(row.sentence)\n",
        "  # print(data[\"data\"][0])\n",
        "  if data:\n",
        "    df.at[row.Index,\"ipa\"]=data[\"data\"][0]\n",
        "  else:\n",
        "    print(row.Index)\n",
        "    print(row.sentence)\n",
        "    break\n",
        "df.to_csv(\"withIPA.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMyUnI8G18Xb"
      },
      "source": [
        "**TESTINS**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "id": "qc3RwWdEvPBW",
        "outputId": "a591655f-35f6-4ef3-9ccc-4e952c20dd2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'amar ʃonar baŋla।'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test connection\n",
        "def call_api (param):\n",
        "    url = f\"http://127.0.0.1:5000//transcribeBanglaTextToIpa?bangla_ipa={param}\"\n",
        "    response = requests.get (url, verify=False)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        return None\n",
        "data=call_api(\"আমার সোনার বাংলা।\")\n",
        "data[\"data\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fills the empty ones\n",
        "subset1_1000=df.iloc[20000:70000]\n",
        "for row in subset1_1000.itertuples():\n",
        "  # print(row.Index)\n",
        "  # print(row[1])\n",
        "  # if pd.notna(row.ipa):\n",
        "  #   continue\n",
        "  # print(row.word)\n",
        "  data=call_api(row.word)\n",
        "  # print(data[\"data\"][0])\n",
        "  if data:\n",
        "    # df.at[row.Index,\"ipa\"]=data[\"data\"][0]\n",
        "    print(f\"{row.Index}:{data['data'][0]}\")\n",
        "  else:\n",
        "    print(row.Index)\n",
        "    print(row.word)\n",
        "    break\n",
        "# df.to_csv(\"withIPA.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3vktnAu0YJD",
        "outputId": "a612773f-d397-478d-9ba0-37709c0ed249"
      },
      "outputs": [],
      "source": [
        "multiprocessing.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "CEcFhqjLISAe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "print(pool.shutdown( cancel_futures=True))\n",
        "df.to_csv(f\"withIPA{start_pos}_{end}.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQLfyQVTgV09",
        "outputId": "2c755c70-1738-430d-b318-e31e099b0ba9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# w0= pool.submit(subset_worker, subsets[0])\n",
        "# w1=pool.submit(subset_worker, subsets[1])\n",
        "# w2=pool.submit(subset_worker, subsets[2])\n",
        "# w3=pool.submit(subset_worker, subsets[3])\n",
        "# w4=pool.submit(subset_worker, subsets[4])\n",
        "# w0.result()\n",
        "# w1.result()\n",
        "# w2.result()\n",
        "# w3.result()\n",
        "# w4.result()\n",
        "\n",
        "# print(w0.cancel())\n",
        "# print(w1.cancel())\n",
        "# print(w2.cancel())\n",
        "# print(w3.cancel())\n",
        "# print(w4.cancel())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7GZigPgFZux"
      },
      "outputs": [],
      "source": [
        "# not working\n",
        "i=500\n",
        "steps=100\n",
        "end=1000\n",
        "subsets=[]\n",
        "while i<end:\n",
        "  subsets.append(df.iloc[i:i+steps])\n",
        "  i=i+steps\n",
        "print(subsets)\n",
        "\n",
        "threads=[]\n",
        "for subset in subsets:\n",
        "  threads.append(threading.Thread(target=subset_worker, daemon=True, args=(subset,)))\n",
        "for thread in threads:\n",
        "  thread.start();\n",
        "  time.sleep(1)\n",
        "for thread in threads:\n",
        "  thread.join()\n",
        "print(\"end\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "58569\n"
          ]
        }
      ],
      "source": [
        "# Unique word clearing\n",
        "df=pd.read_csv(\"bangla_to_ipa_unique_clean2.csv\")\n",
        "df.drop_duplicates(subset=['bangla_token'], inplace=True)\n",
        "print(len(df))\n",
        "df.sort_values('bangla_token').to_csv(\"bangla_to_ipa_unique_clean.csv\",index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "df=pd.read_csv(\"bangla_to_ipa_unique_clean2.csv\")\n",
        "remove=[]\n",
        "for row in df.itertuples():\n",
        "  if len(row.bangla_token)>2 and row.bangla_token[-2]==\"!\":\n",
        "    # print(row.bangla_token[1:])\n",
        "\n",
        "    for i in range(1,110,1):\n",
        "      if df.at[row.Index-i,\"bangla_token\"]==row.bangla_token[:-2]:\n",
        "        print(row.Index)\n",
        "        print(row.bangla_token)\n",
        "        # remove that row\n",
        "        remove.append(row.Index)\n",
        "        break\n",
        "\n",
        "df.drop(remove, inplace=True)\n",
        "print(len(remove))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check whole dataset\n",
        "df=pd.read_csv(\"bangla_to_ipa_unique_clean2.csv\")\n",
        "remove=[]\n",
        "for row in df.itertuples():\n",
        "  if row.bangla_token[:-1]==\"?\":\n",
        "    # if contains in the whole dataset\n",
        "    for i in range(len(df)):\n",
        "      if df.at[i,\"bangla_token\"]==row.bangla_token[:-1]:\n",
        "        print(row.Index)\n",
        "        print(i)\n",
        "        print(row.bangla_token)\n",
        "        # remove that row\n",
        "        remove.append(row.Index)\n",
        "        break\n",
        "df.drop(remove, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.to_csv(\"bangla_to_ipa_unique_clean2.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "angla_to_ipa_unique_clean\n"
          ]
        }
      ],
      "source": [
        "a=\"bangla_to_ipa_unique_clean\"\n",
        "print(a[1:])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
